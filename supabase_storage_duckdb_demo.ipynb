{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BR6HNeWrVaV2"
      },
      "source": [
        "# Supabase Storage and DuckDB: ‚ö°Ô∏è + ü¶Ü = üíö\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "0. [Setup and Installation](#Setup-and-Installation)\n",
        "1. [Query Postgres Data and Export to Supabase Storage](#Query-Postgres-Data-and-Export-to-Supabase-Storage)\n",
        "2. [Query Supabase Storage Directly with DuckDB](#Query-Supabase-Storage-Directly-with-DuckDB)\n",
        "3. [Visualizing Results](#Visualizing-Results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Install Packages\n",
        "comment out the below block if you need to install the packages into your environment (if running locally or in Google Colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install -r https://raw.githubusercontent.com/TylerHillery/supabase-storage-duckdb-demo/main/requirements.txt?token=GHSAT0AAAAAACPZEHJ7KIXE6CPID5MDMUE6ZQSAINQ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we will import the necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "import altair as alt\n",
        "import duckdb\n",
        "from dotenv import load_dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This lines take environment variables from a .env file. If you are not using a .env file feel free to skip it. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will define some variables used for configuration management."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Postgres credentials\n",
        "POSTGRES_HOST = os.getenv(\"POSTGRES_HOST\")\n",
        "POSTGRES_PORT = os.getenv(\"POSTGRES_PORT\")\n",
        "POSTGRES_DATABASE = os.getenv(\"POSTGRES_DATABASE\")\n",
        "POSTGRES_USERNAME = os.getenv(\"POSTGRES_USERNAME\")\n",
        "POSTGRES_PASSWORD = os.getenv(\"POSTGRES_PASSWORD\")\n",
        "\n",
        "# Supabase storage credentials\n",
        "AWS_ACCESS_KEY_ID = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
        "AWS_SECRET_ACCESS_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
        "AWS_REGION = os.getenv(\"AWS_REGION\")\n",
        "BUCKET_URL = os.getenv(\"BUCKET_URL\")\n",
        "ENDPOINT_URL = os.getenv(\"ENDPOINT_URL\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "DuckDB has native support for the [S3 API](https://duckdb.org/docs/extensions/httpfs/s3api.html) and we can use the DuckDB [Secrets Manager](https://duckdb.org/docs/configuration/secrets_manager) to store our credentials "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "duckdb.sql(f\"\"\"\n",
        "DROP SECRET IF EXISTS supabase_storage;\n",
        "CREATE SECRET supabase_storage (\n",
        "    TYPE S3,\n",
        "    KEY_ID '{AWS_ACCESS_KEY_ID}',\n",
        "    SECRET '{AWS_SECRET_ACCESS_KEY}', \n",
        "    ENDPOINT '{ENDPOINT_URL}', \n",
        "    REGION '{AWS_REGION}',\n",
        "    URL_STYLE 'path'\n",
        ")\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load helpful DuckDB Postgres extension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "duckdb.sql(\"INSTALL postgres\")\n",
        "\n",
        "duckdb.sql(f\"\"\"\n",
        "ATTACH \n",
        "    'dbname={POSTGRES_DATABASE} \n",
        "    user={POSTGRES_USERNAME} \n",
        "    host={POSTGRES_HOST} \n",
        "    password={POSTGRES_PASSWORD} \n",
        "    port={POSTGRES_PORT}' \n",
        "AS postgres_db (TYPE POSTGRES, READ_ONLY)\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Query Postgres Data and Export to Supabase Storage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets first query data in our Postgres database and look at some results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "select_pg_customers = \"\"\"\n",
        "SELECT\n",
        "    id                              AS user_id,\n",
        "    first_name                      AS user_first_name,\n",
        "    last_name                       AS user_last_name,\n",
        "    first_name || ' ' || last_name  AS user_full_name,\n",
        "    CURRENT_DATE                    as loaded_at_date,\n",
        "    CURRENT_TIMESTAMP               AS loaded_at_ts_utc\n",
        "FROM \n",
        "    postgres_db.customers \n",
        "\"\"\"\n",
        "duckdb.sql(select_pg_customers).df().head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now lets export those query results to our Supabase Storage bucket as a parquet file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "duckdb.sql(f\"\"\"\n",
        "COPY ({select_pg_customers}) \n",
        "TO '{BUCKET_URL}/customers/{datetime.now().strftime(\"%Y-%m-%d\")}.parquet'\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can do CSV file as well"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "duckdb.sql(f\"\"\"\n",
        "COPY ({select_pg_customers}) \n",
        "TO '{BUCKET_URL}/customers/{datetime.now().strftime(\"%Y-%m-%d\")}.csv'\n",
        "\"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can also do partitioned copies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "duckdb.sql(f\"\"\"\n",
        "COPY ({select_pg_customers}) \n",
        "TO 's3://postgres/customers' (\n",
        "    FORMAT PARQUET,\n",
        "    PARTITION_BY (loaded_at_date),\n",
        "    OVERWRITE_OR_IGNORE true\n",
        ")\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets do the same for the rest of the tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "select_pg_orders = \"\"\"\n",
        "SELECT\n",
        "    id                  AS order_id,\n",
        "    user_id             AS user_id,\n",
        "    order_date          AS order_date,\n",
        "    status              AS order_status,\n",
        "    CURRENT_DATE        AS loaded_at_date,\n",
        "    CURRENT_TIMESTAMP   AS loaded_at_ts_utc\n",
        "FROM \n",
        "    postgres_db.orders\n",
        "\"\"\"\n",
        "duckdb.sql(select_pg_orders).df().head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "duckdb.sql(f\"\"\"\n",
        "COPY ({select_pg_orders}) \n",
        "TO '{BUCKET_URL}/orders/{datetime.now().strftime(\"%Y-%m-%d\")}.parquet'\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "select_pg_payments = \"\"\"\n",
        "SELECT\n",
        "    id                  AS payment_id,\n",
        "    order_id            AS order_id,\n",
        "    payment_method      AS payment_method,\n",
        "    amount              AS order_amount_usd,\n",
        "    CURRENT_DATE        AS loaded_at_date,\n",
        "    CURRENT_TIMESTAMP   AS loaded_at_ts_utc\n",
        "FROM \n",
        "    postgres_db.payments\n",
        "\"\"\"\n",
        "duckdb.sql(select_pg_payments).df().head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "duckdb.sql(f\"\"\"\n",
        "COPY ({select_pg_payments}) \n",
        "TO '{BUCKET_URL}/payments/{datetime.now().strftime(\"%Y-%m-%d\")}.parquet'\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Query Supabase Storage Directly with DuckDB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now the tables are loaded lets query the files from Supabase Storage. We can even do file globbing patterns and return the filename."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "select_from_bucket = f\"\"\"\n",
        "SELECT \n",
        "    filename, \n",
        "    count(*) as record_count\n",
        "FROM \n",
        "    read_parquet('{BUCKET_URL}/orders/*.parquet', filename = true)\n",
        "GROUP BY \n",
        "    ALL\n",
        "\"\"\"\n",
        "duckdb.sql(select_from_bucket).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "join_tables = f\"\"\"\n",
        "SELECT\n",
        "    orders.order_date,\n",
        "    orders.order_id,\n",
        "    customers.user_full_name,\n",
        "    orders.order_status,\n",
        "    payments.payment_method,\n",
        "    payments.order_amount_usd,\n",
        "    customers.user_id,\n",
        "    payments.payment_id\n",
        "FROM\n",
        "    read_parquet('{BUCKET_URL}/orders/*.parquet') AS orders \n",
        "    LEFT JOIN read_parquet('{BUCKET_URL}/customers/*.parquet') AS customers\n",
        "        ON orders.user_id = customers.user_id\n",
        "    LEFT JOIN read_parquet('{BUCKET_URL}/payments/*.parquet') AS payments \n",
        "        ON orders.order_id = payments.order_id\n",
        "\"\"\"\n",
        "orders_df = duckdb.sql(join_tables).df()\n",
        "\n",
        "orders_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizing Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpD-g5jHVgqf"
      },
      "source": [
        "DuckDB can return results in variety of formats such as:\n",
        "- `.fetchall()` returns a list of tuples\n",
        "- `.df()` returns a Pandas DataFrame\n",
        "- `.pl()` returns a Polars DataFrame\n",
        "- `.arrow()` return an Arrow Table \n",
        "- `.fetchnumpy()` returns NumPy Arrays\n",
        "\n",
        "This works nicely with several data viz libraries e.g. Matplotlib, Seaborn, Bokeh. I will be using Altair which is based on Vega-Lite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "monthly_sales = \"\"\"\n",
        "SELECT \n",
        "    date_trunc('month', order_date) as order_month,\n",
        "    sum(order_amount_usd) as sales \n",
        "FROM \n",
        "    orders_df\n",
        "WHERE \n",
        "    order_status != 'returned'\n",
        "GROUP BY \n",
        "    ALL\n",
        "ORDER BY \n",
        "    order_month \n",
        "\"\"\"\n",
        "\n",
        "chart = (\n",
        "    alt.Chart(duckdb.sql(monthly_sales).df())\n",
        "    .mark_line()\n",
        "    .encode(\n",
        "        x=\"order_month\",\n",
        "        y=alt.Y(\"sales\", axis=alt.Axis(format=\"$,.2f\")),\n",
        "        tooltip=[\"order_month\", \"sales\"],\n",
        "    )\n",
        "    .properties(width=750, height=400)\n",
        "    .interactive()\n",
        ")\n",
        "chart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "monthly_sales_by_order_status = \"\"\"\n",
        "SELECT \n",
        "    date_trunc('month', order_date)::string as order_month,\n",
        "    order_status,\n",
        "    sum(order_amount_usd) as sales \n",
        "FROM \n",
        "    orders_df\n",
        "GROUP BY \n",
        "    ALL\n",
        "ORDER BY \n",
        "   order_month \n",
        "\"\"\"\n",
        "\n",
        "chart = (\n",
        "    alt.Chart(duckdb.sql(monthly_sales_by_order_status).df())\n",
        "    .mark_bar()\n",
        "    .encode(\n",
        "        x=\"order_month\",\n",
        "        y=alt.Y(\"sales\", axis=alt.Axis(format=\"$,.2f\")),\n",
        "        tooltip=[\"order_month\", \"sales\", \"order_status\"],\n",
        "        color=\"order_status\",\n",
        "    )\n",
        "    .properties(width=750, height=400)\n",
        "    .interactive()\n",
        ")\n",
        "chart"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyO/Ee1TifGXRy73jEJZpoSn",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
